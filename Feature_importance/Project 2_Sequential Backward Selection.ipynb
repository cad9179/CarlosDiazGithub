{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3 Sequential Backward Selection :Q1\n",
    "Use Sequential Backward Selection Algorithm to find subset of features to archive same accuracy score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:18:46.214417Z",
     "start_time": "2020-11-20T16:18:45.815210Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:18:46.219280Z",
     "start_time": "2020-11-20T16:18:46.216312Z"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:18:47.086958Z",
     "start_time": "2020-11-20T16:18:46.221275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30)\n",
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n",
      " 'mean smoothness' 'mean compactness' 'mean concavity'\n",
      " 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n",
      " 'radius error' 'texture error' 'perimeter error' 'area error'\n",
      " 'smoothness error' 'compactness error' 'concavity error'\n",
      " 'concave points error' 'symmetry error' 'fractal dimension error'\n",
      " 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n",
      " 'worst smoothness' 'worst compactness' 'worst concavity'\n",
      " 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>radius error</th>\n",
       "      <th>texture error</th>\n",
       "      <th>perimeter error</th>\n",
       "      <th>area error</th>\n",
       "      <th>smoothness error</th>\n",
       "      <th>compactness error</th>\n",
       "      <th>concavity error</th>\n",
       "      <th>concave points error</th>\n",
       "      <th>symmetry error</th>\n",
       "      <th>fractal dimension error</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>1.0950</td>\n",
       "      <td>0.9053</td>\n",
       "      <td>8.589</td>\n",
       "      <td>153.40</td>\n",
       "      <td>0.006399</td>\n",
       "      <td>0.04904</td>\n",
       "      <td>0.05373</td>\n",
       "      <td>0.01587</td>\n",
       "      <td>0.03003</td>\n",
       "      <td>0.006193</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>0.5435</td>\n",
       "      <td>0.7339</td>\n",
       "      <td>3.398</td>\n",
       "      <td>74.08</td>\n",
       "      <td>0.005225</td>\n",
       "      <td>0.01308</td>\n",
       "      <td>0.01860</td>\n",
       "      <td>0.01340</td>\n",
       "      <td>0.01389</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>0.7456</td>\n",
       "      <td>0.7869</td>\n",
       "      <td>4.585</td>\n",
       "      <td>94.03</td>\n",
       "      <td>0.006150</td>\n",
       "      <td>0.04006</td>\n",
       "      <td>0.03832</td>\n",
       "      <td>0.02058</td>\n",
       "      <td>0.02250</td>\n",
       "      <td>0.004571</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>0.4956</td>\n",
       "      <td>1.1560</td>\n",
       "      <td>3.445</td>\n",
       "      <td>27.23</td>\n",
       "      <td>0.009110</td>\n",
       "      <td>0.07458</td>\n",
       "      <td>0.05661</td>\n",
       "      <td>0.01867</td>\n",
       "      <td>0.05963</td>\n",
       "      <td>0.009208</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>0.7572</td>\n",
       "      <td>0.7813</td>\n",
       "      <td>5.438</td>\n",
       "      <td>94.44</td>\n",
       "      <td>0.011490</td>\n",
       "      <td>0.02461</td>\n",
       "      <td>0.05688</td>\n",
       "      <td>0.01885</td>\n",
       "      <td>0.01756</td>\n",
       "      <td>0.005115</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>564</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>1.2560</td>\n",
       "      <td>7.673</td>\n",
       "      <td>158.70</td>\n",
       "      <td>0.010300</td>\n",
       "      <td>0.02891</td>\n",
       "      <td>0.05198</td>\n",
       "      <td>0.02454</td>\n",
       "      <td>0.01114</td>\n",
       "      <td>0.004239</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>565</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>0.7655</td>\n",
       "      <td>2.4630</td>\n",
       "      <td>5.203</td>\n",
       "      <td>99.04</td>\n",
       "      <td>0.005769</td>\n",
       "      <td>0.02423</td>\n",
       "      <td>0.03950</td>\n",
       "      <td>0.01678</td>\n",
       "      <td>0.01898</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>566</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>0.4564</td>\n",
       "      <td>1.0750</td>\n",
       "      <td>3.425</td>\n",
       "      <td>48.55</td>\n",
       "      <td>0.005903</td>\n",
       "      <td>0.03731</td>\n",
       "      <td>0.04730</td>\n",
       "      <td>0.01557</td>\n",
       "      <td>0.01318</td>\n",
       "      <td>0.003892</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>567</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>0.7260</td>\n",
       "      <td>1.5950</td>\n",
       "      <td>5.772</td>\n",
       "      <td>86.22</td>\n",
       "      <td>0.006522</td>\n",
       "      <td>0.06158</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.01664</td>\n",
       "      <td>0.02324</td>\n",
       "      <td>0.006185</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>568</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>0.3857</td>\n",
       "      <td>1.4280</td>\n",
       "      <td>2.548</td>\n",
       "      <td>19.15</td>\n",
       "      <td>0.007189</td>\n",
       "      <td>0.00466</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.02676</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean radius mean texture mean perimeter mean area mean smoothness  \\\n",
       "0         17.99        10.38         122.80    1001.0         0.11840   \n",
       "1         20.57        17.77         132.90    1326.0         0.08474   \n",
       "2         19.69        21.25         130.00    1203.0         0.10960   \n",
       "3         11.42        20.38          77.58     386.1         0.14250   \n",
       "4         20.29        14.34         135.10    1297.0         0.10030   \n",
       "..          ...          ...            ...       ...             ...   \n",
       "564       21.56        22.39         142.00    1479.0         0.11100   \n",
       "565       20.13        28.25         131.20    1261.0         0.09780   \n",
       "566       16.60        28.08         108.30     858.1         0.08455   \n",
       "567       20.60        29.33         140.10    1265.0         0.11780   \n",
       "568        7.76        24.54          47.92     181.0         0.05263   \n",
       "\n",
       "    mean compactness mean concavity mean concave points mean symmetry  \\\n",
       "0            0.27760        0.30010             0.14710        0.2419   \n",
       "1            0.07864        0.08690             0.07017        0.1812   \n",
       "2            0.15990        0.19740             0.12790        0.2069   \n",
       "3            0.28390        0.24140             0.10520        0.2597   \n",
       "4            0.13280        0.19800             0.10430        0.1809   \n",
       "..               ...            ...                 ...           ...   \n",
       "564          0.11590        0.24390             0.13890        0.1726   \n",
       "565          0.10340        0.14400             0.09791        0.1752   \n",
       "566          0.10230        0.09251             0.05302        0.1590   \n",
       "567          0.27700        0.35140             0.15200        0.2397   \n",
       "568          0.04362        0.00000             0.00000        0.1587   \n",
       "\n",
       "    mean fractal dimension radius error texture error perimeter error  \\\n",
       "0                  0.07871       1.0950        0.9053           8.589   \n",
       "1                  0.05667       0.5435        0.7339           3.398   \n",
       "2                  0.05999       0.7456        0.7869           4.585   \n",
       "3                  0.09744       0.4956        1.1560           3.445   \n",
       "4                  0.05883       0.7572        0.7813           5.438   \n",
       "..                     ...          ...           ...             ...   \n",
       "564                0.05623       1.1760        1.2560           7.673   \n",
       "565                0.05533       0.7655        2.4630           5.203   \n",
       "566                0.05648       0.4564        1.0750           3.425   \n",
       "567                0.07016       0.7260        1.5950           5.772   \n",
       "568                0.05884       0.3857        1.4280           2.548   \n",
       "\n",
       "    area error smoothness error compactness error concavity error  \\\n",
       "0       153.40         0.006399           0.04904         0.05373   \n",
       "1        74.08         0.005225           0.01308         0.01860   \n",
       "2        94.03         0.006150           0.04006         0.03832   \n",
       "3        27.23         0.009110           0.07458         0.05661   \n",
       "4        94.44         0.011490           0.02461         0.05688   \n",
       "..         ...              ...               ...             ...   \n",
       "564     158.70         0.010300           0.02891         0.05198   \n",
       "565      99.04         0.005769           0.02423         0.03950   \n",
       "566      48.55         0.005903           0.03731         0.04730   \n",
       "567      86.22         0.006522           0.06158         0.07117   \n",
       "568      19.15         0.007189           0.00466         0.00000   \n",
       "\n",
       "    concave points error symmetry error fractal dimension error worst radius  \\\n",
       "0                0.01587        0.03003                0.006193       25.380   \n",
       "1                0.01340        0.01389                0.003532       24.990   \n",
       "2                0.02058        0.02250                0.004571       23.570   \n",
       "3                0.01867        0.05963                0.009208       14.910   \n",
       "4                0.01885        0.01756                0.005115       22.540   \n",
       "..                   ...            ...                     ...          ...   \n",
       "564              0.02454        0.01114                0.004239       25.450   \n",
       "565              0.01678        0.01898                0.002498       23.690   \n",
       "566              0.01557        0.01318                0.003892       18.980   \n",
       "567              0.01664        0.02324                0.006185       25.740   \n",
       "568              0.00000        0.02676                0.002783        9.456   \n",
       "\n",
       "    worst texture worst perimeter worst area worst smoothness  \\\n",
       "0           17.33          184.60     2019.0          0.16220   \n",
       "1           23.41          158.80     1956.0          0.12380   \n",
       "2           25.53          152.50     1709.0          0.14440   \n",
       "3           26.50           98.87      567.7          0.20980   \n",
       "4           16.67          152.20     1575.0          0.13740   \n",
       "..            ...             ...        ...              ...   \n",
       "564         26.40          166.10     2027.0          0.14100   \n",
       "565         38.25          155.00     1731.0          0.11660   \n",
       "566         34.12          126.70     1124.0          0.11390   \n",
       "567         39.42          184.60     1821.0          0.16500   \n",
       "568         30.37           59.16      268.6          0.08996   \n",
       "\n",
       "    worst compactness worst concavity worst concave points worst symmetry  \\\n",
       "0             0.66560          0.7119               0.2654         0.4601   \n",
       "1             0.18660          0.2416               0.1860         0.2750   \n",
       "2             0.42450          0.4504               0.2430         0.3613   \n",
       "3             0.86630          0.6869               0.2575         0.6638   \n",
       "4             0.20500          0.4000               0.1625         0.2364   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.21130          0.4107               0.2216         0.2060   \n",
       "565           0.19220          0.3215               0.1628         0.2572   \n",
       "566           0.30940          0.3403               0.1418         0.2218   \n",
       "567           0.86810          0.9387               0.2650         0.4087   \n",
       "568           0.06444          0.0000               0.0000         0.2871   \n",
       "\n",
       "    worst fractal dimension target  \n",
       "0                   0.11890      0  \n",
       "1                   0.08902      0  \n",
       "2                   0.08758      0  \n",
       "3                   0.17300      0  \n",
       "4                   0.07678      0  \n",
       "..                      ...    ...  \n",
       "564                 0.07115      0  \n",
       "565                 0.06637      0  \n",
       "566                 0.07820      0  \n",
       "567                 0.12400      0  \n",
       "568                 0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# datasetst = load_breast_cancer()\n",
    "databunch = load_breast_cancer() # Python 3.6 allows direct import to dataframe.\n",
    "\n",
    "data = databunch.data\n",
    "\n",
    "print (data.shape)\n",
    "print (databunch.feature_names )\n",
    "\n",
    "df= pd.DataFrame(data=databunch.data, columns=[databunch.feature_names] )\n",
    "df['target'] = pd.Series(databunch.target) \n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:16:17.115376Z",
     "start_time": "2020-11-20T16:16:17.111388Z"
    }
   },
   "source": [
    "Q1-1 Find X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:18:47.092969Z",
     "start_time": "2020-11-20T16:18:47.087956Z"
    }
   },
   "outputs": [],
   "source": [
    "#Enter your code here: :, 1:\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = df.iloc[:,0:30].values, df.iloc[:,30].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1,\n",
       "       1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:18:47.135858Z",
     "start_time": "2020-11-20T16:18:47.128848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      0\n",
       "4      0\n",
       "      ..\n",
       "564    0\n",
       "565    0\n",
       "566    0\n",
       "567    0\n",
       "568    1\n",
       "Length: 569, dtype: int32"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1-2 Split data to training and testing (30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:18:47.179741Z",
     "start_time": "2020-11-20T16:18:47.136827Z"
    }
   },
   "outputs": [],
   "source": [
    "#Enter your code here:\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.3,random_state=0,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bringing features onto the same scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1-3 Standerdize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:18:47.196665Z",
     "start_time": "2020-11-20T16:18:47.182705Z"
    }
   },
   "outputs": [],
   "source": [
    "#Enter your code here:\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "mms = MinMaxScaler()\n",
    "X_train_norm = mms.fit_transform(X_train)\n",
    "X_test_norm = mms.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "stdsc = StandardScaler()\n",
    "X_train_std = stdsc.fit_transform(X_train)\n",
    "X_test_std = stdsc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.26979774, 0.26107541, 0.25757576, ..., 0.1712022 , 0.23679022,\n",
       "        0.14208068],\n",
       "       [0.17282923, 0.81501522, 0.16268317, ..., 0.10341027, 0.26518139,\n",
       "        0.15133758],\n",
       "       [0.33542289, 0.60297599, 0.34720444, ..., 0.58973476, 0.52287066,\n",
       "        0.66963907],\n",
       "       ...,\n",
       "       [0.16499339, 0.17754481, 0.16766254, ..., 0.37030658, 0.34207413,\n",
       "        0.30191083],\n",
       "       [0.2105392 , 0.51335813, 0.21119647, ..., 0.41405443, 0.20366719,\n",
       "        0.23150743],\n",
       "       [0.2301288 , 0.26276632, 0.23275004, ..., 0.3377196 , 0.24704259,\n",
       "        0.48025478]])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_norm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.45981684, 0.58978695, 0.45013515, ..., 0.53565277, 0.28470032,\n",
       "        0.30021231],\n",
       "       [0.24873892, 0.43151843, 0.24043249, ..., 0.32142611, 0.2490142 ,\n",
       "        0.2158811 ],\n",
       "       [0.32122043, 0.42069665, 0.34499929, ..., 0.61488116, 0.25197161,\n",
       "        0.49214437],\n",
       "       ...,\n",
       "       [0.26000294, 0.37436591, 0.25316546, ..., 0.21687909, 0.32137224,\n",
       "        0.07728238],\n",
       "       [0.34864587, 0.16875211, 0.33247973, ..., 0.27402687, 0.15141956,\n",
       "        0.05239915],\n",
       "       [0.09936824, 0.28779168, 0.09112249, ..., 0.        , 0.06762618,\n",
       "        0.08781316]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Selecting meaningful features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential feature selection algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1-4: Define SBS Class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:18:47.216612Z",
     "start_time": "2020-11-20T16:18:47.198660Z"
    }
   },
   "outputs": [],
   "source": [
    "# Enter your code here:\n",
    "\n",
    "from sklearn.base import clone\n",
    "from itertools import combinations\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class SBS():\n",
    "    def __init__(self, estimator, k_features, scoring=accuracy_score,\n",
    "                 test_size=0.25, random_state=1):\n",
    "        self.scoring = scoring\n",
    "        self.estimator = clone(estimator)\n",
    "        self.k_features = k_features\n",
    "        self.test_size = test_size\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = \\\n",
    "            train_test_split(X, y, test_size=self.test_size,\n",
    "                             random_state=self.random_state)\n",
    "\n",
    "        dim = X_train.shape[1]\n",
    "        self.indices_ = tuple(range(dim))\n",
    "        self.subsets_ = [self.indices_]\n",
    "        score = self._calc_score(X_train, y_train, \n",
    "                                 X_test, y_test, self.indices_)\n",
    "        self.scores_ = [score]\n",
    "\n",
    "        while dim > self.k_features:\n",
    "            scores = []\n",
    "            subsets = []\n",
    "\n",
    "            for p in combinations(self.indices_, r=dim - 1):\n",
    "                score = self._calc_score(X_train, y_train, \n",
    "                                         X_test, y_test, p)\n",
    "                scores.append(score)\n",
    "                subsets.append(p)\n",
    "\n",
    "            best = np.argmax(scores)\n",
    "            self.indices_ = subsets[best]\n",
    "            self.subsets_.append(self.indices_)\n",
    "            dim -= 1\n",
    "\n",
    "            self.scores_.append(scores[best])\n",
    "        self.k_score_ = self.scores_[-1]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        return X[:, self.indices_]\n",
    "\n",
    "    def _calc_score(self, X_train, y_train, X_test, y_test, indices):\n",
    "        self.estimator.fit(X_train[:, indices], y_train)\n",
    "        y_pred = self.estimator.predict(X_test[:, indices])\n",
    "        score = self.scoring(y_test, y_pred)\n",
    "        return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1-5: Using KNN, plot Accuracy curve for number of features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "# selecting features\n",
    "sbs = SBS(knn, k_features=1)\n",
    "sbs.fit(X_train_std, y_train)\n",
    "\n",
    "# plotting performance of feature subsets\n",
    "k_feat = [len(k) for k in sbs.subsets_]\n",
    "\n",
    "plt.plot(k_feat, sbs.scores_, marker='o')\n",
    "plt.ylim([0.7, 1.02])\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of features')\n",
    "plt.grid()\n",
    "plt.tight_layout()\n",
    "# plt.savefig('images/04_08.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1-6: List 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiIndex([(          'mean texture',),\n",
      "            (        'mean perimeter',),\n",
      "            (             'mean area',),\n",
      "            (       'mean smoothness',),\n",
      "            (   'mean concave points',),\n",
      "            ('mean fractal dimension',),\n",
      "            (         'texture error',),\n",
      "            (     'compactness error',),\n",
      "            (          'worst radius',),\n",
      "            (     'worst compactness',)],\n",
      "           )\n"
     ]
    }
   ],
   "source": [
    "k3 = list(sbs.subsets_[20])\n",
    "print(df.columns[1:][k3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1-7: Print accuracy score for all features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9798994974874372\n",
      "Test accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "knn.fit(X_train_std, y_train)\n",
    "print('Training accuracy:', knn.score(X_train_std, y_train))\n",
    "print('Test accuracy:', knn.score(X_test_std, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q1-8: Print accuracy score for above 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-20T16:18:49.671046Z",
     "start_time": "2020-11-20T16:18:49.638133Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 0.9773869346733668\n",
      "Test accuracy: 0.935672514619883\n"
     ]
    }
   ],
   "source": [
    "# Enter your code here:\n",
    "knn.fit(X_train_std[:, k3], y_train)\n",
    "print('Training accuracy:',knn.score(X_train_std[:, k3], y_train))\n",
    "\n",
    "print('Test accuracy:',knn.score(X_test_std[:, k3], y_test))"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
